29
transactional memory 事务存储 attempts to simplify concurrent programming by allowing a group of load and store instructions to execute in an atomic way
at runtime, gpu hardware executes groups of scalar threads, called warps 调度器或调度单元 (or wavefronts 波阵面 in amd (advanced micro devices 超微半导体) terminology)
in lockstep 齐步 on simd hardware
discrete gpu: cpu portion of program allocate memory on gpu and initiate transfer of input data into gpu memory, launch a kernel on gpu

30
code carefully optimized for one architecure (gpu) may perform poorly on another (cpu)
single precision scalar value a times vector value x plus vector value y, a * x + y, known as saxpy

32
threads of a compute kernel organized into a grid of thread blocks consisting of warps
warps are grouped into larger unit called cooperative thread array (cta) or thread block by nvidia
assign each thread a portion of data
each thread on gpu lookup its identity within grid of blocks of threads

33
threads within cta communicate with each other via a per compute core scratchpad memory
this scratchpad is called shared memory by nvidia, local data store (lds) by amd's graphics core next (gcn) architecture
allocate memory into scratchpad memory using __shared__ in cuda
scratchpad memory acts as software controlled cache

34
a level of instruction set virtualization via opengl shading language (ogsl)
microsoft's high-level shading language (hlsl)
became common as early gpus became programmable
nvidia high-level instruction set architecture for gpu = parallel thread execution isa (ptx)
limitless set of virtual registers
streaming assembler (sass)
convert ptx to sass can be done by gpu driver or "ptxas" program provided with cuda toolkit

35
/* https://www.cs.uaf.edu/2011/spring/cs641/lecture/03_03_CUDA_PTX.html
cuda "threadIdx.x" is ptx "%tid.x"
cuda "blockIdx.x" is ptx "%ctaid.x"
cuda "blockDim.x" is ptx "%ntid.x"
.reg creates a register with the given type and name:
<n> creates registers numbered 0 through n-1
".reg .f32 %f<3>" creates %f0, %f1, and %f2, all of them 32-bit floats

parallel thread execution isa 32
state space is a storage area with characteristics. all variables reside in some state space
characteristics include size, addressability, access speed, access rights, level of sharing between threads
state spaces:
.sreg: special read-only registers
.global: global memory shared by all threads
.local: local memory private to each thread
.param: kernel parameters, defined per-grid, or function or local parameters, defined per-thread
.shared: addressable memory shared between threads in 1 cta
.tex: global texture memory 纹理存储, 纹理渲染的的图像专用单元 

.pred = predicate 判定 registers, virtual, optional guard predicate (ptx isa 63)
ld = load a register variable form an addressable state space variable (ptx isa 156)
   ld.type d, [a]
   load register variable "d" from the location specified by the source address operand "a" in specified state space
mad = multiply two values, optionally extract high or low half or intermediate result, and add a third value. write result into a dest reg (ptx isa 73)
set = half precision comparison instruction (ptx isa 135)
    set.cmp_op d, a, b
    operand d has type specified by instruction. operands a and b have type .stype
setp = compare two values, optionally combine result with another predicate value by applying a boolean operator. result is written to first dest operand (ptx isa 131)
@ = predicated execution. @(!)p means @p or @!p. the guard predicate follows the optional label and precedes the opcode, and is written as @p, where p is a predicate register (ptx isa 25). execute an instruction for threads that have the guard predicate true (ptx isa 191)
bra = branch to a target and continue execution there (ptx isa 192)
    @p bra target; // direct branch, target is a label
       bra target; // unconditional branch
cvta = convert address from const, global, local, or shared state space to generic, or vice versa (ptx isa 165)
     // convert const, global, local, or shared address to generic address
    cvta.space.size p, a; // source address in register a
    cvta.space.size p, var; // get generic address of var
    cvta.space.size p, var+imm; // generic address of var+offset
    // convert generic address to const, global, local, or shared address
    cvta.to.space.size p, a;
    .space = { .const, .global, .local, .shared };
    .size = { .u32, .u64 };
fma = fused multiply-add with no loss of precision in the intermediate product and addition (ptx isa 128)
      fma d, a, b, c; d = a * b + c
st = store a register variable to an addressable state space variable (ptx isa 161) */
   st.type [a], b
   store the value of register variable "b" in the location specified by the destination address operand "a" in specified state space

36
both ptx and sass are risc
risc = reduced instruction set computer 精简指令集计算机
ptx has infinite set of registers, each definition uses a new register like static single assignment
sass uses a limited set of registers 

streaming assembler (sass) are extracted with nvidia's cuobjdump
https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html
https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html#instruction-set-ref

37
rx  reg
c[x][y] constant mem
s2r special reg to reg (miscellaneous instructions)

generate sass and ptx files:
cuobjdump a.out -sass -ptx

floating point instructions
ffma  floating point 32 fused multiply add
sr_ctaid = special register cooperative thread array id (blockIdx)
sr_tid = special register thread id (threadIdx)
xmad = integer short multiply add instruction
exec = special register used to predicate execution of individual vector lanes for simt execution
